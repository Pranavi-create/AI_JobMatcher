# ğŸ“ Project Directory Structure

```
Project/
â”‚
â”œâ”€â”€ ğŸ“„ Configuration Files
â”‚   â”œâ”€â”€ .env                              # Environment variables (API keys, credentials)
â”‚   â”œâ”€â”€ requirements.txt                  # Python dependencies
â”‚   â”œâ”€â”€ mcp-server-config.json           # MCP server configuration
â”‚   â””â”€â”€ activate_jobly.sh                # Conda environment activation script
â”‚
â”œâ”€â”€ ğŸ¤– Core Pipeline Components
â”‚   â”œâ”€â”€ run_pipeline.py                  # Main automation pipeline (orchestrates all steps)
â”‚   â”œâ”€â”€ job_matcher.py                   # AI-powered job matching engine (Gemini 2.0)
â”‚   â””â”€â”€ send_email_smtp.py               # Gmail SMTP email delivery
â”‚
â”œâ”€â”€ ğŸ”Œ MCP Servers (Claude Desktop Integration)
â”‚   â”œâ”€â”€ job_matcher_mcp_complete.py      # Full-featured MCP server (RECOMMENDED)
â”‚   â”œâ”€â”€ job_matcher_mcp_server.py        # Alternative MCP server
â”‚   â””â”€â”€ job_matcher_mcp_stdio.py         # STDIO-based MCP server
â”‚
â”œâ”€â”€ ğŸ“Š Data Collection Modules
â”‚   â”‚
â”‚   â”œâ”€â”€ linkedin_collector/              # LinkedIn + The Muse Job Search
â”‚   â”‚   â”œâ”€â”€ search_and_save.py          # Main entry point for LinkedIn collection
â”‚   â”‚   â”œâ”€â”€ mcp_server.py               # Async search functions (LinkedIn + The Muse)
â”‚   â”‚   â”œâ”€â”€ linkedin_searcher.py        # LinkedIn API wrapper
â”‚   â”‚   â”œâ”€â”€ job_searcher.py             # The Muse Jobs API wrapper
â”‚   â”‚   â”œâ”€â”€ job_saver.py                # JSON file utilities
â”‚   â”‚   â”œâ”€â”€ job_keywords.txt            # Search keywords configuration
â”‚   â”‚   â”œâ”€â”€ job_matcher.py              # Duplicate matcher (can be removed)
â”‚   â”‚   â”œâ”€â”€ .env                        # LinkedIn credentials
â”‚   â”‚   â””â”€â”€ job_search_results/         # Output: LinkedIn job JSONs
â”‚   â”‚       â”œâ”€â”€ ai_any.json
â”‚   â”‚       â”œâ”€â”€ artificial_intelligence_any.json
â”‚   â”‚       â””â”€â”€ machine_learning_any.json
â”‚   â”‚
â”‚   â”œâ”€â”€ github_collector/                # GitHub Repository Scraper
â”‚   â”‚   â”œâ”€â”€ github_fetcher.py           # Main markdown table parser
â”‚   â”‚   â”œâ”€â”€ github_discovery.py         # Dynamic repo discovery
â”‚   â”‚   â””â”€â”€ README.md                   # Documentation
â”‚   â”‚
â”‚   â””â”€â”€ API_collector/                   # Web Scraping (Firecrawl)
â”‚       â”œâ”€â”€ firecrawl_scraper.py        # LLM-powered scraper
â”‚       â”œâ”€â”€ collect_firecrawl_jobs.py   # Collection script
â”‚       â””â”€â”€ test_firecrawl.py           # Testing utilities
â”‚
â”œâ”€â”€ ğŸ’¾ Data Storage
â”‚   â”œâ”€â”€ data/                            # Job data from GitHub & other sources
â”‚   â”‚   â”œâ”€â”€ jobs_output.json            # GitHub jobs (168 jobs)
â”‚   â”‚   â””â”€â”€ firecrawl_jobs_*.json       # Firecrawl scraped jobs
â”‚   â”‚
â”‚   â””â”€â”€ matched_jobs/                    # AI Matching Results
â”‚       â””â”€â”€ top_50_matches.json         # Top 50 ranked job matches
â”‚
â”œâ”€â”€ ğŸ“‹ Data Models
â”‚   â””â”€â”€ models/
â”‚       â””â”€â”€ job.py                      # Pydantic Job data model (validation)
â”‚
â”œâ”€â”€ ğŸ“„ Resume
â”‚   â””â”€â”€ Resume/
â”‚       â””â”€â”€ Resume_NEW_ML_Pathakota_Pranavi_2.pdf
â”‚
â”œâ”€â”€ ğŸ“š Documentation
â”‚   â”œâ”€â”€ README.md                        # Main project documentation
â”‚   â”œâ”€â”€ DIRECTORY_STRUCTURE.md          # This file
â”‚   â”œâ”€â”€ MCP_INSPECTOR_GUIDE.md          # MCP testing guide
â”‚   â”œâ”€â”€ WEB_INSPECTOR_GUIDE.md          # Web scraping guide
â”‚   â””â”€â”€ *.md                            # Various setup guides
â”‚
â””â”€â”€ ğŸ§ª Testing & Utilities
    â”œâ”€â”€ test_integration.py              # Integration tests
    â””â”€â”€ temp/                           # Temporary files
```

## ğŸ“Š Data Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  1. JOB COLLECTION                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ linkedin_collector/    â†’ job_search_results/*.json         â”‚
â”‚ github_collector/      â†’ data/jobs_output.json             â”‚
â”‚ API_collector/         â†’ data/firecrawl_jobs_*.json        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              2. AI MATCHING (job_matcher.py)                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Loads all jobs from sources                               â”‚
â”‚ â€¢ Extracts resume text from PDF                             â”‚
â”‚ â€¢ Gemini AI scores each job (0-100)                         â”‚
â”‚ â€¢ Generates match reasoning                                 â”‚
â”‚ â€¢ Saves top 50 â†’ matched_jobs/top_50_matches.json          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           3. EMAIL DELIVERY (send_email_smtp.py)            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Reads matched_jobs/top_50_matches.json                    â”‚
â”‚ â€¢ Formats email with job details & scores                   â”‚
â”‚ â€¢ Sends via Gmail SMTP                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”‘ Key Files by Function

### Pipeline Orchestration
- **`run_pipeline.py`** - Main automation script that runs all steps sequentially

### Job Collection
- **`linkedin_collector/search_and_save.py`** - LinkedIn + The Muse job search
- **`github_collector/github_fetcher.py`** - GitHub markdown table parser
- **`API_collector/firecrawl_scraper.py`** - Web scraping (optional)

### AI Matching
- **`job_matcher.py`** - Google Gemini AI matching engine
- **`models/job.py`** - Job data validation model

### Communication
- **`send_email_smtp.py`** - Gmail SMTP delivery
- **`job_matcher_mcp_complete.py`** - Claude Desktop MCP integration

### Configuration
- **`.env`** - API keys (Gemini, LinkedIn, Gmail, Firecrawl)
- **`requirements.txt`** - Python package dependencies
- **`mcp-server-config.json`** - MCP server settings

## ğŸ“ˆ Current Job Counts

| Source | Jobs Collected | Output Location |
|--------|---------------|-----------------|
| **LinkedIn** | ~23 per search | `linkedin_collector/job_search_results/` |
| **The Muse** | ~20 per search | Combined with LinkedIn results |
| **GitHub** | 168 jobs | `data/jobs_output.json` |
| **Firecrawl** | 15 jobs | `data/firecrawl_jobs_*.json` |
| **Total** | ~200-300 | Aggregated from all sources |
| **Matched** | Top 50 | `matched_jobs/top_50_matches.json` |

## ğŸ› ï¸ Technology Stack

- **Python 3.11+** (Conda environment: `jobly`)
- **AI/ML**: Google Gemini 2.0 Flash Experimental
- **APIs**: LinkedIn API, The Muse Jobs API
- **Web Scraping**: Firecrawl, Beautiful Soup, Playwright
- **Data Models**: Pydantic
- **Email**: Gmail SMTP with TLS
- **Protocol**: Model Context Protocol (MCP) for Claude Desktop
- **Async**: asyncio, aiohttp

## ğŸš€ Entry Points

1. **Full Pipeline**: `python run_pipeline.py`
2. **LinkedIn Collection**: `cd linkedin_collector && python search_and_save.py`
3. **GitHub Collection**: `cd github_collector && python github_fetcher.py`
4. **Job Matching**: `python job_matcher.py`
5. **Send Email**: `python send_email_smtp.py`
6. **MCP Server**: Automatically starts with Claude Desktop

## ğŸ“ Output Files

- **`linkedin_collector/job_search_results/*.json`** - Raw LinkedIn + The Muse jobs
- **`data/jobs_output.json`** - GitHub repository jobs
- **`data/firecrawl_jobs_*.json`** - Web-scraped jobs
- **`matched_jobs/top_50_matches.json`** - AI-matched and ranked jobs

---

**Last Updated**: December 4, 2025  
**Project**: CSCE 689 - Programming LLMs - Automated Job Matcher
